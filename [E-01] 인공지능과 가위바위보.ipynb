{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✌가위바위보 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지를 일정한 크기로 변환하는 함수\n",
    "- 불필요한 변환을 막기 위해 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(img_path):\n",
    "    images = glob.glob(img_path + \"/*.jpg\") # 해당 형식의 이름을 가진 파일의 리스트\n",
    "    \n",
    "    target_size = (28, 28)\n",
    "    for img in images:\n",
    "        old_img = Image.open(img)\n",
    "        #불필요한 연산 미시행\n",
    "        if old_img.size == target_size:\n",
    "            continue\n",
    "        new_img = old_img.resize(target_size, Image.ANTIALIAS) #ANTIALIAS ???\n",
    "        new_img.save(img,'JPEG')\n",
    "    print(len(images), \"Image resized to\", target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 경로 지정 및 크기조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1108 Image resized to (28, 28)\n",
      "994 Image resized to (28, 28)\n",
      "1105 Image resized to (28, 28)\n",
      "100 Image resized to (28, 28)\n",
      "100 Image resized to (28, 28)\n",
      "100 Image resized to (28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_path = ['./data/rock_scissor_paper/train/paper',\n",
    "       './data/rock_scissor_paper/train/scissor',\n",
    "       './data/rock_scissor_paper/train/rock']\n",
    "test_path = ['./data/rock_scissor_paper/test/paper',\n",
    "       './data/rock_scissor_paper/test/scissor',\n",
    "       './data/rock_scissor_paper/test/rock']\n",
    "for fp in train_path:\n",
    "    resize_images(fp)\n",
    "for fp in test_path:\n",
    "    resize_images(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 불러오는 함수 정의\n",
    "- 가위, 바위, 보 각 파일의 크기가 달라도 동적으로 불러올 수 있도록 수정\n",
    "- 성능 향상을 위한 graysclae 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_path):\n",
    "    img_size = 28\n",
    "    #garysacale을 활용하기 위해 color=1, dtype=np.uint8로 처리함\n",
    "    color = 1\n",
    "    \n",
    "    # 개수가 다른 가위, 바위, 보가 입력되더라도 처리할 수 있도록 변경\n",
    "    imgs = np.zeros(img_size * img_size * color, dtype = np.uint8).reshape(-1,img_size,img_size,color)\n",
    "    labels = np.zeros(1, dtype=np.uint8)\n",
    "        \n",
    "    for idx, file in enumerate(glob.iglob(img_path+'/scissor/*jpg')) :\n",
    "        img = np.array(Image.open(file).convert('L'), dtype = np.uint8).reshape(-1, img_size, img_size, color)\n",
    "        imgs = np.append(imgs, img, axis = 0)\n",
    "        labels = np.append(labels, 0)\n",
    "        \n",
    "    for idx, file in enumerate(glob.iglob(img_path+'/rock/*jpg')) :\n",
    "        img = np.array(Image.open(file).convert('L'), dtype = np.uint8).reshape(-1, img_size, img_size, color)\n",
    "        imgs = np.append(imgs, img, axis = 0)\n",
    "        labels = np.append(labels, 1)\n",
    "\n",
    "    for idx, file in enumerate(glob.iglob(img_path+'/paper/*jpg')) :\n",
    "        img = np.array(Image.open(file).convert('L'), dtype = np.uint8).reshape(-1, img_size, img_size, color)\n",
    "        imgs = np.append(imgs, img, axis = 0)\n",
    "        labels = np.append(labels, 2)\n",
    "    \n",
    "    #틀을 잡아주었던 첫 행을 제외하고 실제 데이터가 있는 부분만 취함\n",
    "    imgs = imgs[1:]\n",
    "    labels = labels[1:]\n",
    "    \n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터를 불러오기\n",
    "- aiffel에 공유된 3000여 개의 자료로 train하고 직접 만든 가위바위도 300개로 test하도록 데이터를 준비하였음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_shape: (3207, 28, 28, 1)\n",
      "y_train_shape: (3207,)\n",
      "x_test_shape: (300, 28, 28, 1)\n",
      "y_test_shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "image_dir_path_train = './data/rock_scissor_paper/train'\n",
    "image_dir_path_test = './data/rock_scissor_paper/test'\n",
    "\n",
    "x_train, y_train = load_data(image_dir_path_train)\n",
    "x_test, y_test = load_data(image_dir_path_test)\n",
    "\n",
    "x_train_norm = x_train / 255.0\n",
    "x_test_norm = x_test / 255.0\n",
    "\n",
    "#이미 원하는 차원을 가졌으므로 reshape 불필요\n",
    "# x_train_reshaped = x_train_norm.reshape(-1, 28, 28, 3)\n",
    "# x_test_reshaped = x_test_norm.reshape(-1, 28, 28, 3)\n",
    "\n",
    "print(f\"x_train_shape: {x_train_norm.shape}\")\n",
    "print(f\"y_train_shape: {y_train.shape}\")\n",
    "print(f\"x_test_shape: {x_test_norm.shape}\")\n",
    "print(f\"y_test_shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습층 정의\n",
    "- 은닉층의 수를 늘리고, filter수를 64개에서 32개로 줄여 파라미터 수는 줄이되 성능은 높임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 21,027\n",
      "Trainable params: 21,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential( )\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape=(28,28,1) ) )\n",
    "model.add(keras.layers.MaxPool2D((2,2)) )\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation = 'relu') )\n",
    "model.add(keras.layers.MaxPool2D((2,2)) )\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation = 'relu') )\n",
    "model.add(keras.layers.MaxPool2D((2,2)) )\n",
    "\n",
    "model.add(keras.layers.Flatten() )\n",
    "\n",
    "model.add(keras.layers.Dense(32, activation = 'relu') )\n",
    "model.add(keras.layers.Dense(32, activation = 'relu') )\n",
    "model.add(keras.layers.Dense(3, activation='softmax') )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "101/101 [==============================] - 3s 21ms/step - loss: 1.0861 - accuracy: 0.3941\n",
      "Epoch 2/20\n",
      "101/101 [==============================] - 2s 22ms/step - loss: 0.9718 - accuracy: 0.5076\n",
      "Epoch 3/20\n",
      "101/101 [==============================] - 2s 21ms/step - loss: 0.7554 - accuracy: 0.6651\n",
      "Epoch 4/20\n",
      "101/101 [==============================] - 2s 22ms/step - loss: 0.5804 - accuracy: 0.7527\n",
      "Epoch 5/20\n",
      "101/101 [==============================] - 2s 20ms/step - loss: 0.4498 - accuracy: 0.8238\n",
      "Epoch 6/20\n",
      "101/101 [==============================] - 2s 25ms/step - loss: 0.3752 - accuracy: 0.8544\n",
      "Epoch 7/20\n",
      "101/101 [==============================] - 3s 30ms/step - loss: 0.3202 - accuracy: 0.8778\n",
      "Epoch 8/20\n",
      "101/101 [==============================] - 3s 30ms/step - loss: 0.2556 - accuracy: 0.9021\n",
      "Epoch 9/20\n",
      "101/101 [==============================] - 3s 32ms/step - loss: 0.2286 - accuracy: 0.9171 \n",
      "Epoch 10/20\n",
      "101/101 [==============================] - 3s 33ms/step - loss: 0.1824 - accuracy: 0.9333 \n",
      "Epoch 11/20\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.1552 - accuracy: 0.9426\n",
      "Epoch 12/20\n",
      "101/101 [==============================] - 3s 30ms/step - loss: 0.1089 - accuracy: 0.9645\n",
      "Epoch 13/20\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0961 - accuracy: 0.9701\n",
      "Epoch 14/20\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0736 - accuracy: 0.9791 \n",
      "Epoch 15/20\n",
      "101/101 [==============================] - 3s 29ms/step - loss: 0.0735 - accuracy: 0.9738\n",
      "Epoch 16/20\n",
      "101/101 [==============================] - 3s 31ms/step - loss: 0.0856 - accuracy: 0.9707 0s - loss: 0.0907 \n",
      "Epoch 17/20\n",
      "101/101 [==============================] - 3s 32ms/step - loss: 0.0520 - accuracy: 0.9860 0s - loss: 0.0530 - accura\n",
      "Epoch 18/20\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0897 - accuracy: 0.9694\n",
      "Epoch 19/20\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0651 - accuracy: 0.9797\n",
      "Epoch 20/20\n",
      "101/101 [==============================] - 2s 23ms/step - loss: 0.0285 - accuracy: 0.9928 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b12ad93ca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(x_train_norm, y_train, epochs = 20 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결론\n",
    "- 완전히 분리된 train과 test셋으로 0.71의 정확도를 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test)\n",
    "print(test_loss, test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회고\n",
    "- 여러 조건에 따라 accuracy의 variance가 상당히 높았으나 그 이유에 대한 명확한 지식이 없어 어려움을 겪었음\n",
    "- 정적으로 정의된 함수를 동적으로 수행하도록 바꾸면서 코드를 깊이 있게 이해할 수 있었고, 익숙하지 않은 tensorlow를 여러 방향으로 수정해 보면서 직관적인 감각을 느낄 수 있었음\n",
    "- 루브릭 평가 지표를 달성하기 위해 충분한 데이터를 확보하고, GrayScale 변환과 은닉층을 여러차례 수정하여 평가하였음\n",
    "- 그러나 근본적인 이해가 없는 상태에서 지나치게 세밀하게 파고드는 것은 자칫 비효율성을 초래할 수 있음을 느낌\n",
    "- 큰 시야에서 다양한 시도를 할 수 있는 균형을 찾는 것이 중요하다고 생각함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
